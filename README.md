# Hello, my name is Chantal Martinez!
Welcome to my GitHub repository! 

# Outline
[week 1](README.md#week-1-example-report-1)

[week 2](README.md#week-2-example-report-2)

[week 3](README.md#week-3-example-report-3)

[week 4](README.md#week4-example-report-4)

[week 5](README.md#week5-example-report-5)

[week 6](README.md#week6-example-report-6)

[week 7](README.md#week7-example-report-7)

[week 8](README.md#week8-example-report-8)

[week 9](README.md#week9-example-report-9)

[week 10](README.md#week10-example-report-10)

[week 11](README.md#week11-example-report-11)

[week 12](README.md#week12-example-report-12)

---

# Week 12: Report 12 #
## Week of 11/21/2024

**Reflection**

This past week, Iâ€™ve been reflecting on Project 4. Even though my teammates and I had already brainstormed ideas related to learning, disabilities, and other topics, I focused on developing my personal proposal.

<img width="1000" alt="P04 Proposal" src="assets/P04 Proposal.pdf">

Although I am extremely excited about this project and the potential to include it in my portfolio, Iâ€™m a little concerned about the time constraints and how much Iâ€™ll be able to personally contribute. Iâ€™m eager to further develop my skills, but I wonâ€™t be here next week, and the project is due the Monday after Thanksgiving, when Iâ€™ll be unavailable as well. I plan to work as much as I can in the time I have, and Iâ€™m confident it will all come together, but I canâ€™t help feeling a bit anxious about the tight timeline.

**Speculations**

I believe that as educational tools continue to evolve, projects like my math blocks and music toy could become a powerful way to engage children in learning through hands-on interaction. By combining tactile learning with sensory feedback (like sound and light), these kinds of toys could help children not only understand mathematical concepts but also improve their rhythm and music theory knowledge. As the project develops, I speculate that the integration of more advanced sensors and technologies could allow for adaptive learning experiences, where the toy adjusts difficulty levels based on a childâ€™s progress.

Looking ahead, I also think thereâ€™s potential to expand the toyâ€™s application to support other learning areas, such as language or creative problem-solving, making it a versatile tool in early education. I was even thinking about teaching/learning ASL, communication, etc. 

Here is a cool application of what it could be expanded into as well: https://www.tiktok.com/@whataboutbunny/video/7431645317033987359?is_from_webapp=1&sender_device=pc&web_id=7439885197249824299

---

# Week 11: Report 11 #
## Week of 11/14/2024

**Reflection**

This week, I submitted my Project 3 report! It was a big learning curve for me to go from not knowing what an LLM was, to using ZeroWidth, and then creating my own bot that helps me with interviewing. It was a really interesting project, and even though it was relatively short, I was able to learn the basic process behind how agents like these work (or at least, thatâ€™s how I like to think of it).

Looking back at the work and process I followed, I was honestly creeped out when the agent mentioned a project I worked on during my senior year of undergrad, one that isnâ€™t in my portfolio or resume. It was a project I hadn't shared anywhere, which made it feel all the more eerie. This experience really made me realize just how much these agents can learn and know beyond the explicit information we provide them. Itâ€™s unsettling how the model can pull details that seem to go beyond its direct input, which makes me wonder just how much these systems are capable ofâ€”and itâ€™s a bit creepy how it all works.

Here is an updated version of one of my process diagrams, now more specific and explanatory to help clarify whatâ€™s going on in the system. Iâ€™ve made this version more detailed to better illustrate how different components interact and the flow of data throughout the process. For example, Iâ€™ve included clearer steps showing how the Interview Buddy agent takes input from my portfolio, resume, and guidelines, processes that information using ZeroWidth and an LLM, and then generates responses in the first person to simulate a mock interview.

This updated diagram should make it easier for someone unfamiliar with my project or with how LLMs and ZeroWidth workâ€”to follow along. The goal is to show how the system processes and transforms the information to provide real-time, useful feedback in the context of a design interview. By breaking it down this way, I hope to make the technical aspects more accessible and understandable, even for those who havenâ€™t interacted with similar technology before.

<img width="1000" alt="Dia2" src="assets/Dia2.png">

Freha also made me feel realy good about my overall project and it was nice that seh noticed my clean design on the video and pointed it out during our video presentation sessionðŸ˜ŠðŸ¥³. Here are the links to my video and experiments: 

_Video_ - https://youtu.be/n06AOeWpO30

_Exp. 1_ - https://zerowidth.ai/c/demo/GcWnh2lKeAuTAIiIN54r/draft

_Exp. 2_ - https://zerowidth.ai/c/demo/18tsR0raNkfjQ6u6DjfU/draft

_Exp. 3_ - https://zerowidth.ai/c/demo/cJ95mLN5GTYEtA5aB1RY/draft

_Exp. 4_ - https://zerowidth.ai/c/demo/w5NCxhZmNH8jnIM8Wg6M/draft 

_Final Exp._ - https://zerowidth.ai/c/demo/2OmM1Ow1XFzswhRPLDdS/draft

**Speculations**

I believe that as AI and LLMs continue to improve, the line between machine and human interactions in processes like interviews may blur. Itâ€™s possible that, in the future, interviews could be managed by machines, with AI handling both the questions and evaluating responses. However, while machines could handle technical aspects, I think there will still be a need for human involvement to assess qualities like emotional intelligence, creativity, and cultural fitâ€”areas where human judgment remains vital, especially in creative design careers. As these systems advance, we may see hybrid models where machines streamline parts of the process, but humans still play a crucial role in making final decisions.

---

# Week 10: Report 10 #
## Week of 11/07/2024

**Reflection**

After successfully going through the four initial experiments, I brainstormed what I wanted to do for Project 3. Initially, I wanted to work with a Netflix API that would recommend movies, but I wasnâ€™t very motivated about it. I decided to go with something more useful and productive for me outside of classâ€”thatâ€™s how I came up with Interview Buddy!

I was able to create a PDF of my online portfolio, gather my resume, and establish some general guidelines for design interviews. Then, I created my Interview Buddy. At first, it wasnâ€™t responding in the first person or representing my work as I wanted, but after adding the first-person command, it started answering interview questions like magic!

This experiment was both entertaining and a significant learning curve. Before this project, I didnâ€™t fully understand what an LLM or API was. Getting hands-on with the project allowed me to create a tool that will (hopefully) help me prepare for the challenging and frustrating process of securing an internship.

This process is particularly hard for me because my first language is Spanish. Sometimes itâ€™s difficult to think of answers, translate them, and still not respond the way I had imagined. This agent can definitely help me with that, and Iâ€™m really excited to keep using it!

Here are some pictures of my process, diagrams, and even some responses from my agent!

<img width="1000" alt="Dia1" src="assets/Dia1.png">
<img width="1000" alt="Dia3" src="assets/Dia3.png">
<img width="1000" alt="17" src="assets/17.png">
<img width="1000" alt="18" src="assets/18.png">
<img width="1000" alt="19" src="assets/19.png">
<img width="1000" alt="10" src="assets/20.png">

Fingers crossed that it will help me land my dream jobðŸ¤ž!

Moving forward I would tailor the agent to have variables or filters for different companies, roles, etc. actually helping it have more detailed responses. 

**Speculations**

I believe that tools like Interview Buddy have the potential to bridge personal and professional gaps, especially for individuals navigating challenges such as language barriers like I do sometimes. By leveraging AI, these tools can help users to prepare more effectively, boosting confidence in high-pressure scenarios like interviews.

Additionally, I speculate that as LLMs become more advanced, they will play a pivotal role in personal development, making career preparation more accessible and tailored. This aligns with my belief that integrating technology into everyday practices can significantly enhance learning experiences and outcomes.

---

# Week 9: Report 9 #
## Week of 10/31/2024

**Reflection**

Hello, this week we successfully finished project 2 and went on to the third project of the semester. Here are my experiments in ZeroWidth in which I uploaded my resume as knowledge to program the responses to be based on that. 

<img width="1000" alt="Experiments" src="assets/Experiments.png">

_Dem, Oh GPT Experiment 01_

You can see how the temperature affected the response created by ChatGPT.

<img width="333" alt="Experiment 1" src="assets/Experiment 1.png"><img width="333" alt="Experiment 1.1" src="assets/Experiment 1.1.png"><img width="333" alt="Experiment 1.2" src="assets/Experiment 1.2.png">

_Dem, Oh GPT + Instruct Experiment 01_

You can see how the temperature affected the response created by ChatGPT.

<img width="500" alt="Experiment 2" src="assets/Experiment 2.png"><img width="500" alt="Experiment 2.1" src="assets/Experiment 2.1.png">

_Dem, Oh GPT + Instruct + RAG Experiment 01_

<img width="500" alt="Experiment 3" src="assets/Experiment 3.png">

_Dem, Oh GPT + Instruct + RAG+ Variable Experiment 01_

I was getting an error in this experiment, but with Lauryn's help we figured out that my variables in the instructions were in lowercase and not in caps. That fixed it and I was able to see the correct vairables: Chantal Martinez, Skills (Design), and Year (2020). 

<img width="500" alt="Experiment 4" src="assets/Experiment 4.png"><img width="500" alt="Experiments" src="assets/Experiment 4.1.png">

Postman & API Responses

After working on the experiments, I followed TJ's instrusctions to go into Postman and I was able to see the API reponses created while I used Postman to do so. 

<img width="500" alt="Postman" src="assets/Postman.png"><img width="500" alt="API" src="assets/API.png">

**Speculations**

This week, Iâ€™m diving into how LLMs might integrate with the Netflix API to give better, more personalized recommendations. The idea is to use context like Location, Age, Genre, and whether someoneâ€™s more into movies or shows, so the LLM can make suggestions that actually feel relevant to the person. Itâ€™s about making the experience smarter and more connected to real-world preferences and moments. Seeing if LLMs can pull in real-time data like this could be a big step in making recommendations that feel a lot more intuitive.

---

# Week 8: Report 8 #
## Week of 10/24/2024

**Reflection**

This was a very work intensive week in which my team and I worked together to make our interactive Jellyfish successfully work. I modeled the Jellyfish, focused on getting the servo motor to work and fit and designed pieces that could be easily modified if any changes needed to be made. Indeed we had to make various alterations as we made progress due to some changes of sensors. Thankfully, eveyrthing worked out and even by changing out the FSR for and APDS9960 sensor which Kaylee sucessfully connected to P5.js to display an interactive background that  enhanced the sensory experience of our Jellyfish. Here are some pictures of the 3D model and a final group picture of the assembled and working prototype! 

<img width="500" alt="Jelly" src="assets/Jelly.png">
<img width="500" alt="Assembly" src="assets/Assembly.png">
<img width="1000" alt="Render1" src="assets/Render1.png">
<img width="1000" alt="Render2" src="assets/Render2.png">
<img width="1000" alt="Group" src="assets/Group.HEIC">

Although I was really doubtful about this project due to my lack of knowledge on microcontrollers, coding, and all; in the end it was a success and I had a good time working on it.

**Speculations**

This project led me to speculate that in the future, Digital Ecosystems will transform human experiences by creating more interactive and adaptive environments, reshaping how we engage with the world. Engineering will focus on designing intuitive, adaptable products that integrate evolving systems. AI will make these ecosystems smarter, predicting and responding to user behavior in real-time. Ultimately, projects like Jellyfish will seamlessly blend digital and physical interactions, potentially advancing into educational tools which would be a very interesting and engaging development. 

<img width="500" alt="School" src="assets/School.png">

---

# Week 7: Report 7 #
## Week of 10/17/2024

**Reflection**

This week has been a lot of understanding and testing sensors, pieces, and designs. As a group, we have decided not to move forward with MaxcMSP and only focus on TouchDesigner which my teammates are working on. Here are the updated diagrams for the project. Apart from that, we are aiming to include all of the other pices to it so that our Jellyfish is able to vibrate, rotate its tentacles, and light up!

<img width="1000" alt="Chart1" src="assets/Chart1.png">
<img width="1000" alt="Chart2" src="assets/Chart2.png">

I measured and also looked at the specs of the different pieces we will be adding to our project to be able to see if these will fit inside the umbrella-shaped part of our Jellyfish (or the head). I have never worked with gears, nor modeled them so it has been hard to understand how these migth work an dwhat attachment will be added to the servo motor. I looked up various sites that have already modeled pieces and found that it was the best route to go with. I downlowaded stls, imported them into Rhino and have been messing around with them to adjust them and actually making them solids since they were only meshes. Still in the process of making it all fit together, modifying pieces. Here are pictures of the process. 

<img width="1000" alt="Dimensions" src="assets/Dimensions.png">
<img width="1000" alt="Jellyfish" src="assets/Jellyfish.png">

Still need to decided if we will go with regular PLA or resin. The lights might look best with resin, but the PLA might be a better choice if we make the shell thinner. If we use resin, makybe our components might be distacting to anyone interacting with the jellyfish, or it might be cool? Not sure. It is a TBD. 

**Speculations**

In the future (near future) I feel that these tools could perfectly be used in experimential and immersive education. Having interactive simulations in classrooms for learning purposes, will allow students to engage with complex concepts in a hands-on way. This could transform traditional learning environments into dynamic spaces.

As far as for our project, I speculate that if we had more time and expertise, we could use AI to adapt the jellyfish's responses based on user interactions. Integrating it with the Photon2 backdrop could create a cohesive system where both elements respond to each other, enhancing the overall experience. I am not a fan of AI, but it would definitely be a great addition to making this project above and beyond. 

---

# Week 6: Report 6 #
## Week of 10/10/2024

**Reflection**

Hello! This week, I soldered for the first time and worked with Visual Studio Code to play around with my photon2 device. I experimented with the demo firmware and I began exploring how to map sensor values to other processes in the firmware. I experimented with determining appropriate output ranges, particularly for controlling LED brightness based on sensor inputs. I am confident that my second project will have avarious range of sensors, so I am attempting to fet to know as many as I can and asking around what their applications are. Overall, Iâ€™m excited about my progress and starting to feel less scared to use the device, so I am eager to keep exploring the different aplication of this technology. 

Here are some pictures of the the stemma QT interface board that I soldered with a friend. I had never soldered before, but I got help and guidance from Kaylee on how to do it correctly! 

<img width="500" alt="Soldering" src="assets/Soldering.HEIC">
<img width="500" alt="Solder" src="assets/Solder.HEIC">
<img width="500" alt="Soldered" src="assets/Soldered.HEIC">

After doing that, I worked with the two stemma files: ACCEL/GYRO and potentionmeter to OLED. 

<img width="500" alt="Stemma" src="assets/Stemma.HEIC">
<img width="1000" alt="DiagramAccel" src="assets/DiagramAccel.jpg">

We also created our groups for Project 02 and I am very excited. I am working with Kaylee and Lauryn and we have though of created an interactive jellyfish (LED lights and motion) that also has an interactive backdrop made in TouchDesigner. Here is adiagrams of the pieces we will be putting together to make our project come to life!

<img width="1000" alt="PhotonP02" src="assets/PhotonP02.png">

**Speculations**

Moving I sure that these tools have the possibility of being applied into a larger scope than what we are being taught. For example, involving other software platforms like TouchDesigner and MaxMSP to our project sounds so cool. 

<img width="1000" alt="gif" src="assets/gif.gif">

--- 

# Week 5: Report 5 #
## Week of 10/03/2024

**Reflection**

This week I had very limited time to work with the Photon as I had a family emergency and just got back to school. I did follow the tutorials, which personally are very hard to fully understand just because I am not familiar with coding, nor microcontrollers in general. I was able to follow examples in last week's class and was successful; the process of that  in class looked like this: 

<img width="500" alt="Example" src="assets/Example.png">
<img width="500" alt="Example1" src="assets/Example1.png">

This are the tutorials I did:

_**Tutorial #1: Button -> LED Pulse Rate**_

After building the circuit, I found it very insteresting on how the  the location of the cables did affect output of the code. I was able to place them all correctly and success! Afterwards, I went ahead and modified the code: changed the increment in which the LED Pulse flashes. 

<img width="500" alt="LEDPulse" src="assets/LEDPulse.HEIC">
<img width="500" alt="LEDPulse" src="assets/Pulse.HEIC">

_**Tutorial #2: FSR -> LED Color**_

In this next example I encountered a bit of an issue since I had not placed the cables correctly on the top left  part of the circuit. With guidance from a classmate, I was then able to correct it and moved the cables where they were supposed to go. I also found out that there needed to be a certain amount of pressure on the sensor to be able to change the LED color, because at the begiining I was not seeing any type of change other than the LED just lighting up. The colors I saw were Green and Red. 

<img width="500" alt="Color" src="assets/Color.HEIC">
<img width="500" alt="Green" src="assets/Green.HEIC">
<img width="500" alt="Red" src="assets/Red.HEIC">

_**Tutorial #3: Button Send on Change**_

This was very easy to build and very nice to see how my device was connected to the particle website. 

<img width="500" alt="ButtonSend" src="assets/ButtonSend.png">

**Speculations**

I am interested in utilizing different sensors like ultrasonic and motion, and seeing how I can integrate the data into a future interactive project. I am also curious to explore the publish and subscribe functions, and how I can connect two photons and communicate data. I speculate that my future projects will include some interactivity and I am excited to explore how I can utilize the capabilities of two microcontrollers to augment and showcase data. 

This is an example of what I am particularly interested in: wearables, specifically in the health and wellness field! Trying to understand how these work would be amazing, even looking into flexible ones. 

<img width="500" alt="Sensors" src="assets/Sensors.png">

Here is a great article that really caught my eye. Nick is a friend of mine who just graduated from Santa Clara University and his work around "Fluid Movement" is crazy. 

_https://www.scu.edu/news-and-events/feature-stories/2024/stories/fluid-movement.html_

---

# Week 4: Report 4 #
## Week of 09/26/2024

**Reflection**
Hello again! This week was very interesting since it was the first assignment I was submitting for the class. I was very nervous of how I showcased my design aesthetics and design thinking process through such a short video and word-heavy report. I feel that I am a good presenter that can pitch a product very well. But I am so harsh on myself that I always know or feel that there is something I coudl have done better. That is how I felt with my video, since I could not go back and add things like one would naturally do in a presentation which is much more flexible, but still "scripted". 

After watching all the videos and overall oroject of my classmates, I definitely learned that there I things that I can work on to have more successful projects. Now that this first project is done I am excited, but nervous of what is to come.

Additionally, I am very proud of my process of diagramming my first project in Figma, which really helped me understand hwo things in Grasshopper work vs. Rhino. Here is a snapshot of my process:

<img width="1000" alt="TechDesign" src="assets/TechDesign.png">

In class on Monday, I can say that I was little scared and lost. I have never heard or Arduino so I took a workshop a month or so ago so that I wouldn't feel lost in this second project, but I honestly didn't learn much. It was fast paced and basic, but still did not understand how it works. Now being introducd to our second project, I am thankful that it is in groups so I can get my peers to guide me through this learning process. I honestly didn't know the majrority of the terms in the lecture, so we will see how it goes. 

Here is my homework for this week along with the description of how and why I think that these two ecosystems in my life are connected to each other:

<img width="1000" alt="Ecosystems" src="assets/Ecosystems.jpg">

**Speculations**
Speculation of microcontrollers? Not sure, but hopefully the following things will happen:
 - Easier Development Tool: For these tools to have a more user-friendly software could be VERY good for people that do not have a backrgound to know about them. Tools for programming  microcontrollers will become _more intuitive_, with options that _donâ€™t require deep coding skills_, making it easier for anyone to create projects. 
- Advanced Sensors: Microcontrollers might work with cooler sensors that will be developed to make devices smarter for health monitoring among others. _I have a great interest in wearable technology, medical devices, and just overall lifestyle snd wellbeing products and services._

Check out this cool startup I have been following an dbeen interested in for s while: https://www.nextiles.com

---

# Week 3: Report 3 #
## Week of 09/19/2024

**Reflection**
This week was very hectic, trying to understand everything from the project, figuring out what to design, actually using Grasshopper to create somehting I really wanted an already designed, and more! Here are a couple of pictures of the process of Project 01, along with the video I created for this:

<img width="1000" alt="Diagram" src="assets/Rhino_Diagram.jpg">
<img width="1000" alt="Diagram" src="assets/GH_Candle02_Diagram.jpg">
<img width="1000" alt="Diagram" src="assets/GH_Candle02_Diagram.jpg">

Link: https://youtu.be/Aso4vXevdKo 

While I think this was a very fast paced project, I am still open to learning more about Grasshopper and excited to use it in a more complex manner, it will take me some time to grasp how these graphs and flow work. As a designer, it can be challenging not to manipulate my design directly like I can in Rhino or SolidWorks. I am happy to have discovered that leveraging Grasshopper allowed me to iterate and refine my ideas more effectively, improving my overall design process.

After doing my project and video, I wish I had showed more information of all the iterations it took for me to finally land on a design. It definelty was a longer process than what is shown on my video and would really like to get some tips on how to condense this information and be able to still showcase all that I want without leaving important things out. I would like to learn how to explain my diagrams easier on video while still stayingon the 3 min constraint. 

Here are some pictures of the different files created prior to defining the route I was gong to go with and while finding out what works for printing. When working on Grasshopper I found out it was way easier to iterate and doing all this process I did in Rhino while defining what was feasible to print, hold the candle, etc. 

<img width="500" alt="Folders" src="assets/Folders.png">
<img width="500" alt="Iterations" src="assets/IterationsFile.png">
<img width="500" alt="STLs" src="assets/STLs.png">
<img width="500" alt="Prints" src="assets/Prints.png">
<img width="500" alt="Final" src="assets/SmallFinal.png">

I also feel very satisfied to have had the opportunity to help someo of my classmates with Rhino. It felt very nice to be able to give tips and tricks of the programs while others also shared tips and tricks for Grasshopper. 

**Speculations**
I would say that Rhino and Grasshopper will be affected by AI and upgrades in a very positive way. AI technology is advancing and it is very likely that programs like Rhino and Grasshopper will incorporate AI-driven tools that support optimizatio and automated workflows, letting designers/engineers to create complex and innovative solutions in a very efficient manner. Another thing that would be great to be incorporated int he near future would be cloud collaboration. Cloud-based platforms enable real-time collaboration anmong people and introducing it to these porgrams will facilitate teamwork across remote groups that need to work on projects simultaneously. This has pros and cons, since it can enhance productivity, creativity, and offer real-time feedback; yet it can also cause disputes within the same group. Still, it would be a very good addition to the programs. 

---

# Week 2: Report 2 #
## Week of 09/12/2024

**Reflection**
The homework assignment for this week was kind of confusing at first, but after a series of Grasshopper tutorials online and playing around with Grasshopper... I was able to understand the basics of the flow of how the program works (a little bit at least). I feel like it was helpful to mess around with the example files and see what changed in the model once altering the different parameters and baking. I have used Rhino before, so baking was not a term I was familiar with, but it makes sense when you model in Grasshopper that the object or whatever is being created is instantly tranfered into the Rhino file from the Grasshopper graph. While playing around, the program gave me an error once I edited the phone parameters to the actual dimensions of my phone. The center of gravity was off, the stand was not doing its desired function. Below are some picturs of my progress:

<img width="500" alt="Edits" src="assets/Edits.png">
<img width="500" alt="Position" src="assets/Position.png">
<img width="500" alt="Error" src="assets/Error.png">

Here is a visual/diagram of what I understood from the example files of the phone stand:

<img width="1000" alt="Diagram" src="assets/Grasshopper Diagram.png">

And here is another visual of my thinking process while trying to create something: 

<img width="1000" alt="Rhino_Sketch" src="assets/Rhino_Sketch.png">

In class on Monday we had a Grasshopper demo that was more "clear" (still a work in progress to understand how it works) than many tutorials. I have still been watching tutorials that show some "tips and tricks" to helpe first time user get familiar with the commands and all you can do in the program. While it is still hard to grasp all the commands, paraments, etc. I am confident that I will learn how to do basic models soon. Here is a picture of the progress I made with the "live tutorial" that TJ led the other day...

<img width="500" alt="GH_Example" src="assets/GH_Example.png">

I feel that I need more practice to figure out what is the gemometry (not sure this is the correct term) that is available in Grasshopper. I have had a difficult time differentiating between types of commands. For example, I want to do a a circle, but there are so many options... how do I know which one is the one I want? I feel that it will be a trial and error learning experience and then it will be total muscle memory. Fingers crossed! Very excited to develop this knowledge and skil in this new program. 

Examples: 

<img width="250" height="400" alt="Circle" src="assets/Circle.png">
<img width="250" height="400" alt="Vector" src="assets/Vector.png">

**Speculations**
Grasshopper seems very intimidating, but I do think this is a tool that can be used in different field in the future. It might be hard for deisgners ot go into Grasshopper after wprking with other programs before, but if someone that is very organized and visualizes a design or solution in a "graph" it will be a very helpful tool for them. Computational design tools are definetly growing and will help deisgners, engineers, etc. in the iteration and manufacturing processes of solutions.  

---

# Week 1: Report 1 #
## Week of 09/05/2024

**Reflection**
This week it was a mix of going back to basics and learning things. After a year or so of not being in a studio, using CAD, or physically prototypiong, it feels good to be back. After refreshing my knowledge on Rhino, laser cutting, and 3D printing, I decided to test out the laser cutter for this first week. 

I went the simple route creating coasters for my new apartment and they turned out pretty good! I worked in Rhino and then moved onto Illustartor, where I faced some issues with having a newer version of the program. With some guidance from Cody Glen, I was able to succesfully cut my coasters. See pictures of my design below!

<img width="500" alt="Rhino" src="assets/Rhino Screenshot.png">
<img width="500" alt="Illustrator" src="assets/Illustrator Screenshot.png">

After cutting the coasters I felt happy to be back in a workshop, yet felt the necessity to seal them/clear coat them to make these functional... here are some pictures of the process...

<img width="500" alt="Laser Cutting Process" src="assets/Cutting.HEIC">
<img width="500" alt="Stain" src="assets/Stain.HEIC">
<img width="500" alt="Stained" src="assets/Stained.HEIC">

**Speculations**
Moving forward, I see myself working on very interesting projects and getting familiar with both old and new machines/tools. All the tools we are being offered and pushed to use seem to be very useful and purposeful for our future as designers. 

Additionally, I am very interested in the healthcare industry. Medical tech, wearables, everything related to it... I recently read on the news about this doctor in China who performed surgery on a patient from kilometers away. I really finds this fascinating, find the link below:

_https://www.hindustantimes.com/trending/doctor-removes-patient-s-lung-tumor-while-operating-machine-from-5-000-km-away-video-surfaces-101722674450882.html_
